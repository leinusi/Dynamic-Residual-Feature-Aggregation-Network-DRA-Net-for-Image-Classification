{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa98e5-c06d-4959-a636-215c2618e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, RandomHorizontalFlip, RandomCrop\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, RandomHorizontalFlip, RandomCrop\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#可变线性层+升维马尔科夫转移过程\n",
    "class AdaptiveWeightsNet(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(AdaptiveWeightsNet, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feature_dim, feature_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim // 2, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, features):\n",
    "        weights = self.mlp(features)\n",
    "        return weights\n",
    "    \n",
    "class DistanceMetric(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(DistanceMetric, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feature_dim * 2, feature_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, attractor1, attractor2):\n",
    "        combined_features = torch.cat((attractor1, attractor2), dim=1)\n",
    "        distance = self.mlp(combined_features)\n",
    "        return distance\n",
    "\n",
    "class ModifiedFeatureExtractor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ModifiedFeatureExtractor, self).__init__()\n",
    "        self.model = resnet18(pretrained=pretrained)\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pretrained:\n",
    "            # 在预训练模式下,使用完整的模型\n",
    "            x = self.model(x)\n",
    "        else:\n",
    "            # 在特征提取模式下,使用除去最后一层的模型\n",
    "            x = nn.Sequential(*list(self.model.children())[:-1])(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "        return x\n",
    "\n",
    "    def remove_last_layer(self):\n",
    "        # 移除最后一层,用于特征提取\n",
    "        self.pretrained = False\n",
    "\n",
    "class DynamicResidualFeatureAggregationNetwork(nn.Module):\n",
    "    def __init__(self, num_classes, feature_dim, high_dim):\n",
    "        super(DynamicResidualFeatureAggregationNetwork, self).__init__()\n",
    "        self.attractors = nn.Parameter(torch.zeros(num_classes, high_dim))\n",
    "        nn.init.kaiming_normal_(self.attractors, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        self.linear1 = nn.Linear(feature_dim, high_dim)\n",
    "        self.linear2 = nn.Linear(high_dim, feature_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feature_dim, feature_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(feature_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "        self.distance_metric = DistanceMetric(high_dim)\n",
    "        self.adaptive_weights_net = AdaptiveWeightsNet(high_dim, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        features_high = self.linear1(features)\n",
    "        adaptive_weights = self.adaptive_weights_net(features_high)\n",
    "        weighted_attractors = self.attractors * adaptive_weights.unsqueeze(2)\n",
    "        aggregated_features_high = torch.bmm(adaptive_weights.unsqueeze(1), weighted_attractors).squeeze(1)\n",
    "        aggregated_features = self.linear2(aggregated_features_high)\n",
    "        combined_features = features + aggregated_features\n",
    "        processed_features = self.mlp(combined_features)\n",
    "        return processed_features\n",
    "\n",
    "    def regularize_attractors(self):\n",
    "        reg_loss = 0\n",
    "        num_attractors = self.attractors.size(0)\n",
    "        for i in range(num_attractors - 1):\n",
    "            for j in range(i + 1, num_attractors):\n",
    "                distance = self.distance_metric(self.attractors[i:i+1], self.attractors[j:j+1])\n",
    "                reg_loss += distance.squeeze()\n",
    "        reg_loss /= (num_attractors * (num_attractors - 1) / 2)\n",
    "        return reg_loss\n",
    "\n",
    "    def calculate_intra_class_compactness(self, features, labels):\n",
    "        \"\"\"计算类内紧致度\"\"\"\n",
    "        unique_labels = torch.unique(labels)\n",
    "        compactness = 0.0\n",
    "        for label in unique_labels:\n",
    "            class_features = features[labels == label]\n",
    "            class_mean = torch.mean(class_features, dim=0, keepdim=True)\n",
    "            compactness += torch.mean(torch.norm(class_features - class_mean, dim=1)) / len(unique_labels)\n",
    "        return compactness\n",
    "    \n",
    "    def calculate_inter_class_distance(self, features, labels):\n",
    "        \"\"\"计算类间距离(使用余弦相似度)\"\"\"\n",
    "        unique_labels = torch.unique(labels)\n",
    "        class_centers = []\n",
    "        for label in unique_labels:\n",
    "            class_features = features[labels == label]\n",
    "            class_center = torch.mean(class_features, dim=0, keepdim=True)\n",
    "            class_centers.append(class_center)\n",
    "        class_centers = torch.cat(class_centers, dim=0)\n",
    "\n",
    "        # 计算类中心之间的余弦相似度\n",
    "        distance = 0.0\n",
    "        n = len(class_centers)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                cos_sim = F.cosine_similarity(class_centers[i], class_centers[j], dim=0)\n",
    "                distance += (1 - cos_sim) / (n * (n - 1) / 2)  # 使用1-cos_sim来转换相似度为距离\n",
    "        return distance\n",
    "\n",
    "class LearningModelTrainer:\n",
    "    def __init__(self, feature_extractor, attention_attractor_net, config):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.feature_extractor = feature_extractor.to(self.device)\n",
    "        self.attention_attractor_net = attention_attractor_net.to(self.device)\n",
    "        self.config = config\n",
    "\n",
    "    def pretrain_feature_extractor(self, loader):\n",
    "        # 预训练特征提取器,此时的特征提取器包含全连接层\n",
    "        optimizer = optim.SGD(self.feature_extractor.parameters(), lr=self.config[\"lr\"], momentum=0.9)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.feature_extractor.train()\n",
    "        for epoch in range(self.config[\"pretrain_epochs\"]):\n",
    "            for i, (images, labels) in enumerate(loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.feature_extractor(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(f\"Pretrain Epoch [{epoch+1}/{self.config['pretrain_epochs']}], Step [{i+1}/{len(loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    def train_attractor_network(self, loader):\n",
    "        self.feature_extractor.eval()  # 设置特征提取器为评估模式\n",
    "        optimizer = optim.AdamW(self.attention_attractor_net.parameters(), lr=self.config[\"meta_lr\"])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        lambda_reg = self.config[\"lambda_reg\"]\n",
    "\n",
    "        for epoch in range(self.config[\"attraction_epochs\"]):\n",
    "            total_loss_accumulated = 0  # 累积损失,用于日志\n",
    "            for j, (images, labels) in enumerate(loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "                # 获取特征表示\n",
    "                with torch.no_grad():  # 不更新特征提取器的梯度\n",
    "                    features = self.feature_extractor(images)\n",
    "            \n",
    "                # 计算吸引子网络的输出和分类损失\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.attention_attractor_net(features)\n",
    "                classification_loss = criterion(outputs, labels)\n",
    "            \n",
    "                # 计算正则化损失\n",
    "                reg_loss = self.attention_attractor_net.regularize_attractors()\n",
    "\n",
    "                # 计算总损失并进行反向传播\n",
    "                total_loss = classification_loss + lambda_reg * reg_loss\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss_accumulated += total_loss.item()\n",
    "\n",
    "                if (j + 1) % 100 == 0:\n",
    "                    avg_loss = total_loss_accumulated / 100\n",
    "                    print(f\"Attraction Epoch [{epoch+1}/{self.config['attraction_epochs']}], Step [{j+1}/{len(loader)}], Avg Loss over last 100 steps: {avg_loss:.4f}\")\n",
    "                    total_loss_accumulated = 0  # 重置累积损失\n",
    "\n",
    "    def evaluate_accuracy(self, loader):\n",
    "        self.feature_extractor.eval()\n",
    "        self.attention_attractor_net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                features = self.feature_extractor(images)\n",
    "                outputs = self.attention_attractor_net(features)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Accuracy on the test dataset: {accuracy * 100:.2f}%')\n",
    "\n",
    "    def visualize_features(self, loader):\n",
    "        self.feature_extractor.eval()\n",
    "        self.attention_attractor_net.eval()\n",
    "        \n",
    "        features_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                features = self.feature_extractor(images)\n",
    "                features_list.append(features.cpu().numpy())\n",
    "                labels_list.append(labels.cpu().numpy())\n",
    "                \n",
    "        # Concatenate lists to form arrays\n",
    "        features_array = np.concatenate(features_list, axis=0)\n",
    "        labels_array = np.concatenate(labels_list, axis=0)\n",
    "        \n",
    "        # Apply t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=123)\n",
    "        reduced_features = tsne.fit_transform(features_array)\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        colors = plt.cm.winter(np.linspace(0, 1, len(np.unique(labels_array))))  # Use the 'winter' colormap\n",
    "\n",
    "        for i, color in zip(np.unique(labels_array), colors):\n",
    "            indexes = labels_array == i\n",
    "            plt.scatter(reduced_features[indexes, 0], reduced_features[indexes, 1], label=i, color=color)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title(\"Features Visualization using t-SNE\")\n",
    "        plt.grid(True)  # Add a grid for a more standard look\n",
    "        plt.savefig(\"features_tsne_visualization.png\")\n",
    "\n",
    "    def evaluate_metrics(self, loader):\n",
    "        self.feature_extractor.eval()\n",
    "        self.attention_attractor_net.eval()\n",
    "        features_list = []\n",
    "        labels_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                features = self.feature_extractor(images)\n",
    "                features_list.append(features)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "        features = torch.cat(features_list, dim=0)\n",
    "        labels = torch.cat(labels_list, dim=0)\n",
    "        \n",
    "        # 计算并打印类内紧致度和类间距离\n",
    "        compactness = self.attention_attractor_net.calculate_intra_class_compactness(features, labels)\n",
    "        inter_class_distance = self.attention_attractor_net.calculate_inter_class_distance(features, labels)\n",
    "        print(f\"Class Intra-Compactness: {compactness.item():.4f}\")\n",
    "        print(f\"Inter-Class Distance: {inter_class_distance.item():.4f}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    transform = Compose([\n",
    "        Resize((224, 224)),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    feature_extractor = ModifiedFeatureExtractor(pretrained=True)\n",
    "    attention_attractor_net = DynamicResidualFeatureAggregationNetwork(num_classes=10, feature_dim=512, high_dim=1024)  \n",
    "\n",
    "    config = {\n",
    "        \"lr\": 0.01,\n",
    "        \"pretrain_epochs\": 3,\n",
    "        \"attraction_epochs\": 2,\n",
    "        \"batch_size\": 32,\n",
    "        \"meta_lr\": 0.001,\n",
    "        \"lambda_reg\": 0.001,\n",
    "    }\n",
    "\n",
    "    trainer = LearningModelTrainer(feature_extractor, attention_attractor_net, config)\n",
    "\n",
    "    print(\"开始预训练特征提取器...\")\n",
    "    trainer.pretrain_feature_extractor(train_loader)\n",
    "\n",
    "    feature_extractor.remove_last_layer()\n",
    "\n",
    "    print(\"开始训练吸引子网络...\")\n",
    "    trainer.train_attractor_network(train_loader)  # 注意这里使用的是train_loader\n",
    "\n",
    "    print(\"评估模型性能...\")\n",
    "    trainer.evaluate_accuracy(test_loader)  # 注意这里使用的是test_loader\n",
    "    \n",
    "    print(\"可视化特征...\")\n",
    "    trainer.visualize_features(test_loader)\n",
    "    trainer.evaluate_metrics(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
